{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:39:36.206093Z",
     "start_time": "2023-07-11T16:39:34.400639Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'aapl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=f'log/{symbol}.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:46:05.131697Z",
     "start_time": "2023-07-11T16:46:03.675276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>combined</th>\n",
       "      <th>is_removed</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7nca41</td>\n",
       "      <td>2018-01-01 01:04:25</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>alreadyinuse5000</td>\n",
       "      <td>Blowing versus sucking</td>\n",
       "      <td>AAPL just entered a contract to purchase 51 of...</td>\n",
       "      <td>/r/wallstreetbets/comments/7nca41/blowing_vers...</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>Blowing versus sucking AAPL just entered a con...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7nfzp3</td>\n",
       "      <td>2018-01-01 16:37:41</td>\n",
       "      <td>RobinHood</td>\n",
       "      <td>CardinalNumber</td>\n",
       "      <td>The 2018 /r/Robinhood Stock Picking Game</td>\n",
       "      <td># tl;dr\\n\\n - Stock picking game will last all...</td>\n",
       "      <td>/r/RobinHood/comments/7nfzp3/the_2018_rrobinho...</td>\n",
       "      <td>https://www.reddit.com/r/RobinHood/comments/7n...</td>\n",
       "      <td>The 2018 /r/Robinhood Stock Picking Game # tl;...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7nhc2r</td>\n",
       "      <td>2018-01-01 20:21:33</td>\n",
       "      <td>investing</td>\n",
       "      <td>InvestingLifeSavings</td>\n",
       "      <td>Hesitant to invest in $AAPL</td>\n",
       "      <td>Looking at AAPLs fundamentals and the pile of ...</td>\n",
       "      <td>/r/investing/comments/7nhc2r/hesitant_to_inves...</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/7n...</td>\n",
       "      <td>Hesitant to invest in $AAPL Looking at AAPLs f...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7nhwud</td>\n",
       "      <td>2018-01-01 21:54:14</td>\n",
       "      <td>stocks</td>\n",
       "      <td>Djg35</td>\n",
       "      <td>Stock mix help required (ETF)</td>\n",
       "      <td>I’ve decided I’m most likely interested in jus...</td>\n",
       "      <td>/r/stocks/comments/7nhwud/stock_mix_help_requi...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/7nhwu...</td>\n",
       "      <td>Stock mix help required (ETF) I’ve decided I’m...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ni0o7</td>\n",
       "      <td>2018-01-01 22:12:01</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Djg35</td>\n",
       "      <td>ETF advice please!</td>\n",
       "      <td>I’ve decided I’m most likely interested in jus...</td>\n",
       "      <td>/r/personalfinance/comments/7ni0o7/etf_advice_...</td>\n",
       "      <td>https://www.reddit.com/r/personalfinance/comme...</td>\n",
       "      <td>ETF advice please! I’ve decided I’m most likel...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          created_utc        subreddit                author  \\\n",
       "0  7nca41  2018-01-01 01:04:25   wallstreetbets      alreadyinuse5000   \n",
       "1  7nfzp3  2018-01-01 16:37:41        RobinHood        CardinalNumber   \n",
       "2  7nhc2r  2018-01-01 20:21:33        investing  InvestingLifeSavings   \n",
       "3  7nhwud  2018-01-01 21:54:14           stocks                 Djg35   \n",
       "4  7ni0o7  2018-01-01 22:12:01  personalfinance                 Djg35   \n",
       "\n",
       "                                      title  \\\n",
       "0                    Blowing versus sucking   \n",
       "1  The 2018 /r/Robinhood Stock Picking Game   \n",
       "2               Hesitant to invest in $AAPL   \n",
       "3             Stock mix help required (ETF)   \n",
       "4                        ETF advice please!   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  AAPL just entered a contract to purchase 51 of...   \n",
       "1  # tl;dr\\n\\n - Stock picking game will last all...   \n",
       "2  Looking at AAPLs fundamentals and the pile of ...   \n",
       "3  I’ve decided I’m most likely interested in jus...   \n",
       "4  I’ve decided I’m most likely interested in jus...   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/wallstreetbets/comments/7nca41/blowing_vers...   \n",
       "1  /r/RobinHood/comments/7nfzp3/the_2018_rrobinho...   \n",
       "2  /r/investing/comments/7nhc2r/hesitant_to_inves...   \n",
       "3  /r/stocks/comments/7nhwud/stock_mix_help_requi...   \n",
       "4  /r/personalfinance/comments/7ni0o7/etf_advice_...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/wallstreetbets/commen...   \n",
       "1  https://www.reddit.com/r/RobinHood/comments/7n...   \n",
       "2  https://www.reddit.com/r/investing/comments/7n...   \n",
       "3  https://www.reddit.com/r/stocks/comments/7nhwu...   \n",
       "4  https://www.reddit.com/r/personalfinance/comme...   \n",
       "\n",
       "                                            combined  is_removed  is_deleted  \n",
       "0  Blowing versus sucking AAPL just entered a con...       False       False  \n",
       "1  The 2018 /r/Robinhood Stock Picking Game # tl;...       False       False  \n",
       "2  Hesitant to invest in $AAPL Looking at AAPLs f...       False       False  \n",
       "3  Stock mix help required (ETF) I’ve decided I’m...       False       False  \n",
       "4  ETF advice please! I’ve decided I’m most likel...       False       False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'prepared/{symbol}.csv').drop(['stock_symbol'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('sentiment'):\n",
    "    os.makedirs('sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentiment using vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:41:34.770974Z",
     "start_time": "2023-07-11T16:41:29.035269Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:42:19.362768Z",
     "start_time": "2023-07-11T16:42:19.023219Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:42:21.470707Z",
     "start_time": "2023-07-11T16:42:21.465718Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "total = len(df['combined'])\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    global counter\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        logging.info(f\"vader:{timestamp}: {counter}/{total}, {counter/total*100}%\")\n",
    "    \n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:53:04.714336Z",
     "start_time": "2023-07-11T16:47:01.451826Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39306/39306 [02:28<00:00, 264.10it/s] \n"
     ]
    }
   ],
   "source": [
    "# df['sentiment_vader'] = df['combined'].apply(get_sentiment)\n",
    "df['polarity_vader'] = df['combined'].progress_apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'sentiment/{symbol}_sentiment.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentiment using pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:58:28.236868Z",
     "start_time": "2023-07-11T16:58:00.776687Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pattern.en import sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:58:59.165444Z",
     "start_time": "2023-07-11T16:58:59.162337Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "def get_sentiment(text):\n",
    "    global counter\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        logging.info(f\"pattern:{timestamp}: {counter}/{total}, {counter/total*100}%\")\n",
    "    \n",
    "    return sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-11T17:20:24.416809Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39306/39306 [02:28<00:00, 265.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df['pattern_temp'] = df['combined'].progress_apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['polarity_pattern', 'subjectivity_pattern']] = df['pattern_temp'].apply(pd.Series)\n",
    "df = df.drop(['pattern_temp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'sentiment/{symbol}_sentiment.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentiment using CardiffNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_src = 'cardiffnlp/twitter-xlm-roberta-base-sentiment'\n",
    "\n",
    "nlp = AutoModelForSequenceClassification.from_pretrained(model_src)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_src)\n",
    "config = AutoConfig.from_pretrained(model_src)\n",
    "\n",
    "tokenizer.save_pretrained(model_src)\n",
    "nlp.save_pretrained(model_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:58:59.165444Z",
     "start_time": "2023-07-11T16:58:59.162337Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "def get_sentiment(text):    \n",
    "    global counter\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        logging.info(f\"cardiff:{timestamp}: {counter}/{total}, {counter/total*100}%\")\n",
    "    \n",
    "    if len(text) > 512: text = text[:512]\n",
    "    \n",
    "    token = tokenizer(text, return_tensors='pt')\n",
    "    output = nlp(**token)\n",
    "    scores = softmax(output[0][0].detach().numpy())\n",
    "    \n",
    "    return (scores[0] * -1) + scores[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-11T17:20:24.416809Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39306/39306 [54:32<00:00, 12.01it/s]  \n"
     ]
    }
   ],
   "source": [
    "df['polarity_bert'] = df['combined'].progress_apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'sentiment/{symbol}_sentiment.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentiment using textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:58:28.236868Z",
     "start_time": "2023-07-11T16:58:00.776687Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:58:59.165444Z",
     "start_time": "2023-07-11T16:58:59.162337Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "\n",
    "# def get_sentiment(text):\n",
    "#     global counter\n",
    "    \n",
    "#     counter += 1\n",
    "#     if counter % 1000 == 0:\n",
    "#         timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#         logging.info(f\"textblob:{timestamp}: {counter}/{total}, {counter/total*100}%\")\n",
    "    \n",
    "#     return TextBlob(text).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-11T17:20:24.416809Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df['textblob_temp'] = df['combined'].progress_apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['polarity_textblob', 'subjectivity_textblob']] = df['textblob_temp'].apply(pd.Series)\n",
    "# df = df.drop(['textblob_temp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'sentiment/{symbol}_sentiment.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentiment using flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:58:28.236868Z",
     "start_time": "2023-07-11T16:58:00.776687Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from flair.data import Sentence\n",
    "# from flair.nn import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T16:58:59.165444Z",
     "start_time": "2023-07-11T16:58:59.162337Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "\n",
    "# def get_sentiment(text):\n",
    "#     global counter\n",
    "#     sentence = Sentence(text)\n",
    "#     tagger = Classifier.load('sentiment-fast')\n",
    "#     tagger.predict(sentence)\n",
    "\n",
    "#     label = sentence.labels[0].value\n",
    "#     score = sentence.labels[0].score\n",
    "    \n",
    "#     counter += 1\n",
    "#     if counter % 1000 == 0:\n",
    "#         timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#         logging.info(f\"flair:{timestamp}: {counter}/{total}, {counter/total*100}%\")\n",
    "    \n",
    "#     return score if label == 'POSITIVE' else -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-11T17:20:24.416809Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df['sentiment_flair'] = df['combined'].apply(get_sentiment)\n",
    "# df['sentiment_flair'] = df['combined'].progress_apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'sentiment/{symbol}_sentiment.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
